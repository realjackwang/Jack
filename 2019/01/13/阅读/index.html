<!DOCTYPE HTML>
<html lang="null">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="Hexo">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->





<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->


<title>ASC准备工作 | Hexo</title>


    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="John Doe">
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                 <img src="/img/branding.png" alt="Snippet 博客主题" class="img-responsive center-block">
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">Hexo</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>Home</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/前端/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/后端/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/工具/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>时间轴</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="ASC准备工作">
            
	            ASC准备工作
            
        </h1>
        <div class="post-meta">
    
    
    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a href="/categories/ ">
             
        </a>
    </span>
    

    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
                
            
        </span>
    </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/01/13</span>
        </span>
        
            <span class="fa-wrap">
                <i class="fa fa-eye"></i>
                <span id="busuanzi_value_page_pv"></span>
            </span>
        
    
</div>

            
            
    </div>
    
    <div class="post-body post-content">
        <h1 id="ASC-Student-Supercomputer-Challenge-2019-Preliminary-Contest-Notifications"><a href="#ASC-Student-Supercomputer-Challenge-2019-Preliminary-Contest-Notifications" class="headerlink" title="ASC Student Supercomputer Challenge (2019)Preliminary Contest Notifications"></a>ASC Student Supercomputer Challenge (2019)Preliminary Contest Notifications</h1><h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>一、学校或院系超级计算机活动简介（5分）</p>
<p>二、团队介绍（5分）</p>
<p>三、技术要求（90分）</p>
<ol>
<li><p><strong>设计一个HPC系统（15分）</strong></p>
</li>
<li><p><strong>HPL和HPCG（15分）</strong></p>
</li>
<li><p><strong>单图像超分辨率挑战（30分</strong>）</p>
<p><strong>简介</strong></p>
<p>在本次比赛中，参赛者需要设计一种算法，使用深度学习等SOTA策略对使用双三次核下采样的图像进行4x SR上标。例如。4倍放大后的400x600图像的分辨率为1600x2400。评估将以感知质量感知的方式进行。pim2018[^4]中定义的感知指数(perception index, PI)将用于计算重建的高分辨率图像的质量。PI越低，重建图像的质量越高。Ma和NIOE是两种无参考图像质量度量[^5-6]。<br>$$<br>Perceptual \ index = \frac { 1 } { 2 } ( ( 10 - M a ) + N I Q E )<br>$$<br>每队提交80张重建的高分辨率图像进行评分测试。</p>
<p>对于初始和最终阶段，每个团队还应该提交一个文件夹，其中包含可以重现测试结果的源代码和模型。</p>
<p>| Folder Name                             | Contents                             |<br>| ————————————— | ———————————— |<br>| Single Image Super Resolution Challenge | Root directory                       |<br>| HR_images                               | reconstructed high-resolution images |<br>| script                                  | PyTorch source code here             |<br>| model                                   | PyTorch model here                   |</p>
<p><strong>评判标准</strong></p>
<p>score = S~PI~ + S~prop~<br>$$<br>S _ { P I } = \frac { 20 } { \left( P I / P I _ { \min } \right) ^ { 4 } }<br>$$</p>
<ol>
<li><p>参与者应该注意RMSE应该位于8 &lt;RMSE &lt; 18的范围内，否则S~PI~为0</p>
</li>
<li><p>S~prop~是委员会根据参与者的提案给出的分数。最大S~prop~为10。鼓励参与者详细描述他们的神经网络设计和网络性能</p>
</li>
</ol>
<p><strong>The participants must use <a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch</a> framework for this task</strong></p>
</li>
<li><p><strong>CESM测试（30分）</strong></p>
<p><strong>简介</strong></p>
<p>在气候建模社区广泛使用的模型中，社区地球系统模型(community Earth System Model, CESM)已成为世界上最流行的气候模型之一，广泛应用于气候变化、气候预测和气候变化的各种研究。</p>
<p>CESM是一个完全耦合的、社区的、全球气候模型，它提供了最先进的计算机模拟地球的过去。礼物。以及未来的气候状况。CESM是全球大约12个气候模型之一，可以用来模拟地球气候系统的许多组成部分，包括海洋、大气。海冰和陆地覆盖。使用CESM。研究人员现在可以模拟海洋生态系统与温室气体的相互作用:臭氧对气候的影响。尘埃和其他大气化学物质:碳在大气、海洋中的循环。陆地表面:以及温室气体对上层大气的影响。</p>
<p>CESM各组成部分的数学原理和算法在参考文献[^1]和[^2]中有详细描述。我们建议使用稳定版本的cesm1.2.2，其源代码可在参考[^3]中获得。关于CESM的安装和使用的更多信息可以从参考[^4]中找到。</p>
<p><strong>评判标准</strong></p>
<p>评价我们可以使用CESM和RMSE的诊断包来评估模型结果</p>
<p>CESM的诊断包可以获得每个变量的气候学和年变异性。</p>
<p>我们用500hPa位势高度作为代表。然后计算模型结果与观测数据之间的RMSE<br>$$<br>\mathrm { RMSE } = \sqrt { \frac { \sum _ { t = 1 } ^ { n } \left( x _ { 1 , t } - x _ { 2 , t } \right) ^ { 2 } } { n } }<br>$$</p>
</li>
</ol>
<h1 id="Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution"><a href="#Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution" class="headerlink" title="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"></a>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</h1><blockquote>
<p>参考：</p>
<p><a href="https://www.jianshu.com/p/b728752a70e9" target="_blank" rel="noopener">基于感知损失函数的实时风格转换和超分辨率重建 (zhwhong)</a></p>
<p><a href="https://www.jianshu.com/p/fe0c149ea806" target="_blank" rel="noopener">深度学习可以做哪些有趣的事情？</a></p>
</blockquote>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>摘要：</strong>我们考虑的图像转换的问题，即将一个输入图像变换成一个输出图像。最近热门的图像转换的方法通常是训练前馈卷积神经网络，将输出图像与原本图像的逐像素差距作为损失函数。并行的工作表明，高质量的图像可以通过用预训练好的网络提取高级特征、定义并优化感知损失函数来产生。我们组合了一下这两种方法各自的优势，提出采用感知损失函数训练前馈网络进行图像转换的任务。本文给出了图像风格化的结果，训练一个前馈网络去解决实时优化问题（Gatys等人提出的），和基于有优化的方法对比，我们的网络产生质量相当的结果，却能做到三个数量级的提速。我们还实验了单图的超分辨率重建，同样采用感知损失函数来代替求逐像素差距的损失函数</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><strong>我们的系统由两部分组成：</strong></p>
<p>一个<strong>图片转换网络f~w~</strong> </p>
<p>一个<strong>损失网络 φ</strong>（用来定义一系列损失函数l1, l2, l3）</p>
<p>图片转换网络是一个<strong>深度残差网络</strong></p>
<p>参数是权重W，它把输入的图片x通过映射 y=f~w~(x)转换成输出图片y，每一个损失函数计算一个标量值li(y,y~i~), 衡量输出的y和目标图像y~i~之间的差距。</p>
<p>图片转换网络是用<strong>SGD</strong>训练，使得一系列损失函数的加权和保持下降</p>
<p><img src="https://upload-images.jianshu.io/upload_images/145616-16427bfcaab71f02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="图2：系统概览。左侧是Generator，右侧是预训练好的vgg16网络(一直固定)"></p>
<p>损失网络对比生成网络生成的图片与每一幅训练集中的目标图片</p>
<p>损失函数可表示为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/145616-ca7f24d7d863f854.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p>
<p><strong>网络设计：</strong></p>
<ol>
<li><p>我们不用任何的池化层，取而代之的是用<strong>步幅卷积</strong>或微步幅卷积</p>
</li>
<li><p>我们的神经网络有<strong>五个残差块</strong>[42]组成，用了[44]说的结构。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/5300364-f8e8898da3e5c066.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/538/format/webp" alt="img"></p>
</li>
<li><p>所有的非残差卷积层都跟着一个空间性的batch-normalization和RELU的非线性层，最末的输出层除外。</p>
</li>
<li><p>最末层使用一个缩放的Tanh来确保输出图像的像素在[0,255]之间。</p>
</li>
<li>第一个和最后一个卷积层使用9×9的核，其他卷积层使用3×3的核。</li>
</ol>
<p><strong>输入和输出：</strong>对于风格转换，输入和输出都是彩色图片，大小3x256x256。对于超分辨率重建，有一个上采样因子f，输出是一个高分辨率的图像3x288x288，输入是一个低分辨率图像 3x288/fx288/f，因为图像转换网络是完全卷积，所以在测试过程中它可以被应用到任何分辨率的图像中。</p>
<p><strong>下采样和上采样：</strong>对于超分辨率重建，有一个上采样因子f，我们用了几个残差块跟着Log2f卷及网络（stride=1/2）。这个处理和[1]中不一样，[1]在把输入放进网络之前使用了双立方插值去上采样这个低分辨率输入。不依赖于任何一个固定的上采样插值函数，微步长卷积允许上采样函数和网络的其他部分一起被训练。</p>
<p><strong>单图超分辨率重建：</strong></p>
<p>在单图超分辨率重建中，任务是从一个低分辨率的输入，去产生一个高分辨率的输出图片。这是一个固有的病态问题，因为对一个低分辨率图像，有可能对应着很多种高分辨率的图像。当超分辨率因子变大时，这个不确定性会变得更大。对于更大的因子（x4 x8），高分辨率图像中的好的细节很可能只有一丁点或者根本没有出现在它的低分辨率版本中。</p>
<p>为了解决这个问题，我们训练了超分辨率重建网络，不使用过去使用的逐像素差损失函数，取而代之的是一个<strong>特征重建损失函数</strong>（看section 3）以保证语义信息可以从预训练好的损失网络中转移到超分辨率网络。我们重点关注x4和x8的超分辨率重建，因为更大的因子需要更多的语义信息。</p>
<p>传统的指标来衡量超分辨率的是PSNR和SSIM，两者都和人类的视觉质量没什么相关的[55,56,57,58,59].PSNR和SSIM仅仅依赖于像素间低层次的差别，并在高斯噪声的相乘下作用，这可能是无效的超分辨率。另外的，PSNR是相当于逐像素差的，所以用PSNR衡量的模型训练过程是让逐像素损失最小化。因此我们强调，这些实验的目标并不是实现先进的PSNR和SSIM结果，而是展示定性的质量差别（逐像素损失函数vs感知损失）</p>
<p><strong>模型细节：</strong>我们训练模型来完成x4和x8的超分辨率重建，通过最小化特征损失（用vgg16在relu2_2层提取出），用了288x288的小块（1万张MSCOCO训练集），准备了低分辨率的输入，用高斯核模糊的（σ=1.0）下采样用了双立方插值。我们训练时bacth-size=4，训练了20万次，Adam，学习速率0.001，无权重衰减，无dropout。作为一个后续处理步骤，我们执行网络输出和低分辨率输入的直方图匹配。</p>
<p><strong>基础：</strong>基本模型我们用的 SRCNN[1] 为了它优秀的表现，SRCNN是一个三层的卷积网络，损失函数是逐像素求差，用的ILSVRC2013数据集中的33x33的图片。SRCNN没有训练到x8倍，所以我们只能评估x4时的差异。</p>
<p>SRCNN训练了超过1亿次迭代，这在我们的模型上是不可能实现的。考虑到二者的差异（SRCNN和我们的模型），在数据，训练，结构上的差异。我们训练图片转换网络x4,x8用了逐像素求差的损失函数，这些网络使用相同搞得数据，结构，训练网络去减少lfeat</p>
<p><strong>评测：</strong>我们评测了模型，在标准的集合5，集合6，BSD100数据集，我们报告的PSNR和SSIM[54]，都只计算了在Y通道上的（当转换成YCbCr颜色空间后），跟[1,39]一样。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这篇文章中，我们结合了前馈网络和基于优化的方法的好处，通过用感知损失函数来训练前馈网络。我们对风格转换应用了这个方法达到了很好的表现和速度。对超分辨率重建运用了这个方法，证明了用感知损失来训练，能带来更多好的细节和边缘。</p>
<p>未来的工作中，我们期望把感知损失函数用在更多其他的图像转换任务中，如上色或者语义检测。我们还打算研究不同损失网络用于不同的任务，或者更多种不同的语义信息的数据集</p>
<h1 id="Photo-Realistic-Single-Image-Super-Resolution-Using-a-Generative-Adversarial-Network"><a href="#Photo-Realistic-Single-Image-Super-Resolution-Using-a-Generative-Adversarial-Network" class="headerlink" title="Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"></a>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</h1><h2 id="网络结构图（SRGAN）"><a href="#网络结构图（SRGAN）" class="headerlink" title="网络结构图（SRGAN）"></a>网络结构图（SRGAN）</h2><p><img src="https://upload-images.jianshu.io/upload_images/8771353-415f53eb0c6ee4ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/539/format/webp" alt="img"></p>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p>ISR是高分辨率图像，ILR是低分辨率图像，是由高分辨率图像先加高斯噪声然后经过一个r步长的下采样得到的，所以高低分辨率的图像大小分别是：rW x rH x C和W x H x C。</p>
<p>模型的目的就是生成网络G可以将输入的低分辨率图像重构出ISR，所以在生成器时就采用前馈CNN记作Gθ，参数是θ，那么此部分要优化的就是：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-0b599f50ab2dc551.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/305/format/webp" alt="img"></p>
<p>和标准GAN一样，模型需要训练下式：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-1ac16d9f1b365ae2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp" alt="img"></p>
<p>生成网络的结构如下，核心是下面的B残差块部分，重复的残差块用于生成高分辨率图像，然后接着两个亚像素卷积层用于恢复高分辨率图像的尺寸。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-0bdab0f240cde072.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/539/format/webp" alt="img"></p>
<p>判别网络的结构如下图，连续的卷积层、BN和Leaky ReLU，紧接着是稠密块和SIGMOD用于对图像分类。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-1e0f0c73c5d4094c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/539/format/webp" alt="img"></p>
<p>SRGAN的创新点在于 loss函数分为两部分</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-1d6768bef7c5c714.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/299/format/webp" alt="img"></p>
<ul>
<li>内容损失</li>
<li>对抗损失</li>
</ul>
<p><strong>内容损失</strong></p>
<p>传统的loss都是以像素为单位的MSE，MSE的loss函数使得输出缺乏高频成分，过于光滑不适宜人们阅读。</p>
<p>所以本文在基于预训练的VGG19的RELU激活层来定义loss函数：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-7cb65e4ef1ac0b7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/352/format/webp" alt="img"></p>
<p><strong>对抗损失</strong></p>
<p>生成图像被判别为高分辨率图像的概率：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/8771353-47f6835b6a2876e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/220/format/webp" alt="img"></p>
<h2 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h2><ul>
<li><p>用均方误差优化SRResNet，能够得到具有很高的峰值信噪比的结果。</p>
</li>
<li><p>在训练好的VGG模型的高层特征上计算感知损失来优化SRGAN，并结合SRGAN的判别网络，能够得到峰值信噪比虽然不是最高，但是具有逼真视觉效果的结果，基于VGG模型高层特征比基于VGG模型低层特征的内容损失能生成更好的纹理细节。</p>
</li>
</ul>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="" target="_blank">Snippet</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2019/01/13/我的电脑上有哪些神奇的软件/" class="pre-post btn btn-default" title="">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs"></span>
        </a>
    
    
        <a href="/2019/01/13/hello-world/" class="next-post btn btn-default" title="Hello World">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Hello World</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: 'xOKV9J4UeQAtVkvnJC7Kq2Jn-gzGzoHsz',
            appKey: 'erIpQac4azoCmgfBB7Dl9maa',
            placeholder: '说点什么吧',
            notify: false,
            verify: false,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'null'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">Table of Contents</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ASC-Student-Supercomputer-Challenge-2019-Preliminary-Contest-Notifications"><span class="toc-text">ASC Student Supercomputer Challenge (2019)Preliminary Contest Notifications</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#要求"><span class="toc-text">要求</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution"><span class="toc-text">Perceptual Losses for Real-Time Style Transfer and Super-Resolution</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论"><span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Photo-Realistic-Single-Image-Super-Resolution-Using-a-Generative-Adversarial-Network"><span class="toc-text">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#网络结构图（SRGAN）"><span class="toc-text">网络结构图（SRGAN）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法-1"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论-1"><span class="toc-text">结论</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
        Total:
        <strong id="busuanzi_value_site_pv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
        &nbsp; | &nbsp;
        Visitors:
        <strong id="busuanzi_value_site_uv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2017
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>






    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>